{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpOu+bc4nUkfL8Qe3EsQ2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a52c998298f4d63b804047864d2f184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30d276c8fdf14ab7a831b51b1d102588",
              "IPY_MODEL_8c19fb87d5894768940924944ec2f45e",
              "IPY_MODEL_f7676891a7ad44a1850be301526a93e3"
            ],
            "layout": "IPY_MODEL_490ddc81033843ffae29e11252cb6fb9"
          }
        },
        "30d276c8fdf14ab7a831b51b1d102588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6691b70ab07042ccbd86366ea819165e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4d062ab984e441f987118322da4f8356",
            "value": "Map:‚Äá100%"
          }
        },
        "8c19fb87d5894768940924944ec2f45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55722fd798db4408a27f3d9debcfb3bf",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7264ad68ee284869a92270b15c8ab61a",
            "value": 2000
          }
        },
        "f7676891a7ad44a1850be301526a93e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3451543f2c934398a449e172f8b9aa87",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f45c52ae33fc431f9e4e5bc008e5709d",
            "value": "‚Äá2000/2000‚Äá[00:00&lt;00:00,‚Äá17414.37‚Äáexamples/s]"
          }
        },
        "490ddc81033843ffae29e11252cb6fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6691b70ab07042ccbd86366ea819165e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d062ab984e441f987118322da4f8356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55722fd798db4408a27f3d9debcfb3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7264ad68ee284869a92270b15c8ab61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3451543f2c934398a449e172f8b9aa87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45c52ae33fc431f9e4e5bc008e5709d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7a753a333a74b8f92330c94cf9bb0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66720a852a254107bb3ed29e52ab9f58",
              "IPY_MODEL_93caec6a66014a3c8cb3147f34e111e9",
              "IPY_MODEL_8a1e9781977a407f92b6a74293552bd3"
            ],
            "layout": "IPY_MODEL_239a38e751954eef8af02b391f627e84"
          }
        },
        "66720a852a254107bb3ed29e52ab9f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95671c4f79c4301a60e67705ddc93a6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0fff679c0dfe476d86ac060d08aacfc9",
            "value": "Map:‚Äá100%"
          }
        },
        "93caec6a66014a3c8cb3147f34e111e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f097bac04d72439da4477ffacd579281",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5388a1cbe86145ae98c78311e4b71172",
            "value": 2000
          }
        },
        "8a1e9781977a407f92b6a74293552bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ad083d21bc483c9d13b197fa540dd2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0ffccdb54c65468c9be6c469a6f4053b",
            "value": "‚Äá2000/2000‚Äá[00:01&lt;00:00,‚Äá1574.18‚Äáexamples/s]"
          }
        },
        "239a38e751954eef8af02b391f627e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95671c4f79c4301a60e67705ddc93a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fff679c0dfe476d86ac060d08aacfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f097bac04d72439da4477ffacd579281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5388a1cbe86145ae98c78311e4b71172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97ad083d21bc483c9d13b197fa540dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ffccdb54c65468c9be6c469a6f4053b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunchach/transformers_demo/blob/main/Prompt_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Install necessary libraries\n",
        "!pip install -q transformers datasets peft accelerate\n",
        "!pip install huggingface_hub\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDMF_DWpZsFj",
        "outputId": "51937f24-a4e9-4dc7-f87e-8f04dd2b11f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "GE66TAcp1q7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = userdata.get('OpenAI_keys')  # Replace with your key"
      ],
      "metadata": {
        "id": "rvl7v7RK1vNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Imports\n",
        "import openai\n",
        "import numpy as np\n",
        "import os\n",
        "import tiktoken\n",
        "from google.colab import userdata\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "from datasets import load_dataset\n",
        "from peft import PromptTuningConfig, PromptTuningInit, get_peft_model, TaskType"
      ],
      "metadata": {
        "id": "NxHLM1pk1apm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "dyNLECZPZtBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text to analyze\n",
        "text = \"Hello ChatGPT myself Varun\"\n",
        "\n",
        "# 1. Tokenization using tiktoken (same tokenizer used by OpenAI)\n",
        "encoding = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
        "tokens = encoding.encode(text)\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Number of Tokens:\", len(tokens))\n",
        "print(\"Token IDs:\", tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "gsUPCmsuZsAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ccb8c0-dcd7-4b2c-c28e-839657602ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello ChatGPT myself Varun\n",
            "Number of Tokens: 7\n",
            "Token IDs: [9906, 13149, 38, 2898, 7182, 8909, 359]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings"
      ],
      "metadata": {
        "id": "3TKluqGrZyKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Get Embeddings from OpenAI\n",
        "response = openai.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=text\n",
        ")\n",
        "\n",
        "embedding = response.data[0].embedding\n",
        "\n",
        "print(\"\\nLength of Embedding Vector:\", len(embedding))\n",
        "print(\"First 5 Dimensions of Embedding Vector:\", embedding[:5])"
      ],
      "metadata": {
        "id": "68zXb5BlZr20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105d5ca8-497b-4140-a02f-08a1d5942c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Length of Embedding Vector: 1536\n",
            "First 5 Dimensions of Embedding Vector: [-0.023479679599404335, 0.0009394785156473517, 0.022358132526278496, -0.012548228725790977, -0.0032444780226796865]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define cosine similarity\n",
        "def cosine_similarity(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "# Words from same and different semantic groups\n",
        "group_fruit = [\"mango\", \"banana\"]\n",
        "group_profession = [\"doctor\", \"engineer\"]\n",
        "\n",
        "# Combine all words\n",
        "all_words = group_fruit + group_profession\n",
        "\n",
        "# Get embeddings\n",
        "response = openai.embeddings.create(\n",
        "    model=\"text-embedding-3-large\",\n",
        "    input=all_words\n",
        ")\n",
        "\n",
        "# Store embeddings in a dictionary\n",
        "embeddings = {word: res.embedding for word, res in zip(all_words, response.data)}\n",
        "\n",
        "# Compare similarities\n",
        "similar_same_group = cosine_similarity(embeddings[\"mango\"], embeddings[\"banana\"])\n",
        "similar_diff_group = cosine_similarity(embeddings[\"mango\"], embeddings[\"doctor\"])\n",
        "\n",
        "# Display results\n",
        "print(f\"Cosine Similarity (Same Group - 'mango' vs 'banana'): {similar_same_group:.4f}\")\n",
        "print(f\"Cosine Similarity (Different Group - 'mango' vs 'doctor'): {similar_diff_group:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN6-WMR_0Can",
        "outputId": "f2c43ed4-ea0d-4020-8f11-94ce24493867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity (Same Group - 'mango' vs 'banana'): 0.5327\n",
            "Cosine Similarity (Different Group - 'mango' vs 'doctor'): 0.2639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üîÑ **Prompt Drift in LLMs**\n",
        "\n",
        "### üß† What is Prompt Drift?\n",
        "\n",
        "* When the **same prompt** yields **different outputs** over time\n",
        "* Caused by **model updates**, **randomness**, or **context changes**\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è Causes of Prompt Drift\n",
        "\n",
        "* üß¨ **Model updates** or LLM migrations\n",
        "* üì• Changes in **prompt injection** or RAG data\n",
        "* üé≤ LLM‚Äôs **creative randomness**\n",
        "* üîÅ **Prompt chaining** leading to cascading inaccuracies\n",
        "* üß≠ Off-topic **model tangents or biases**\n",
        "\n",
        "---\n",
        "\n",
        "### üö® Impact of Prompt Drift\n",
        "\n",
        "* ‚ùå **Inconsistent responses** across sessions\n",
        "* üìâ **Reduced reliability** in production systems\n",
        "* üß™ **Hard to test/debug** for developers\n",
        "\n",
        "---\n",
        "\n",
        "### üõ†Ô∏è Mitigation Strategies\n",
        "\n",
        "* üß™ Regular **prompt testing & benchmarking**\n",
        "* üìã Use of **comprehensive templates**\n",
        "* üß† Stronger **in-context learning (ICL)**\n",
        "* üìà Continuous **monitoring & logging**\n"
      ],
      "metadata": {
        "id": "cDhVXY9QZ7gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_model(prompt, model):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "ETYCmDFcZrtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain me results for Ind vs Pak finals 2007.\"\n",
        "\n",
        "# Compare across versions (if available to you)\n",
        "models = [\"gpt-3.5-turbo\", \"gpt-4-turbo\"]\n",
        "for model in models:\n",
        "    print(f\"\\nüß† Model: {model}\")\n",
        "    print(call_model(prompt, model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_X5V0b9bfX_",
        "outputId": "40496d99-59ae-4849-b584-0e422d7bd4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Model: gpt-3.5-turbo\n",
            "In the 2007 ICC World Twenty20 final between India and Pakistan, India emerged victorious by defeating Pakistan by 5 runs. India batted first and scored 157/5 in their 20 overs, with Gautam Gambhir top-scoring with 75 runs. In response, Pakistan managed to score 152/7 in their 20 overs, falling short of the target by 5 runs. Irfan Pathan was the pick of the Indian bowlers, taking 3 wickets for 16 runs. This victory marked India's first-ever win in a World T20 final and further added to the intense rivalry between the two cricketing nations.\n",
            "\n",
            "üß† Model: gpt-4-turbo\n",
            "The India vs. Pakistan final in the 2007 ICC World Twenty20 held in South Africa is one of the most memorable matches in the history of cricket, particularly in the T20 format. The match took place on September 24, 2007, at the Wanderers Stadium in Johannesburg.\n",
            "\n",
            "### Match Summary:\n",
            "- **Toss**: India won the toss and chose to bat first.\n",
            "- **India's Innings**: India posted a total of 157/5 in their 20 overs. Gautam Gambhir was the top scorer with 75 runs off 54 balls, a crucial innings that included eight fours and two sixes. Rohit Sharma also contributed significantly with a quick 30 off 16 balls towards the end. Pakistan's bowling attack was led by Umar Gul who took 3 wickets for 28 runs in his 4 overs.\n",
            "- **Pakistan's Innings**: In response, Pakistan started well but lost wickets at crucial intervals. Misbah-ul-Haq played a vital knock for Pakistan, scoring 43 runs off 38 balls. However, Pakistan kept losing wickets and were eventually left needing 13 runs off the final over with one wicket in hand.\n",
            "- **The Final Over**: The final over of the match was bowled by Joginder Sharma for India. Despite starting the over with a wide ball, the situation became tense with Pakistan needing 6 runs from 4 balls. Misbah-ul-Haq tried to scoop a delivery over fine leg, but the ball went high into the air only to be caught by Sreesanth, sealing the victory for India.\n",
            "- **Result**: India won the match by 5 runs and clinched the inaugural ICC World Twenty20 trophy.\n",
            "\n",
            "### Key Performances:\n",
            "- **Gautam Gambhir**: His 75-run knock was instrumental in setting up a competitive total for India.\n",
            "- **Irfan Pathan**: He was named the Man of the Match for his crucial bowling performance, taking 3 wickets for 16 runs in his 4 overs.\n",
            "- **Misbah-ul-Haq**: Despite being on the losing side, his fighting innings almost took Pakistan to victory.\n",
            "\n",
            "### Significance:\n",
            "This win was significant for Indian cricket as it marked the emergence of a new generation of players. It was also India's first major ICC trophy win since the 1983 World Cup. The match is remembered for its high drama and the nail-biting finish that ultimately showcased the thrill and unpredictability associated with the T20 format. The victory also sparked a massive surge in the popularity of T20 cricket in India, eventually leading to the creation of the Indian Premier League in 2008.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **üß† Memory Handling in LLMs**\n",
        "\n",
        "---\n",
        "\n",
        "#### üìå Why Memory Matters:\n",
        "\n",
        "* Enables **context retention** in conversations\n",
        "* Supports **factual consistency** and task tracking\n",
        "* Combines short-term and long-term memory strategies\n",
        "\n",
        "---\n",
        "\n",
        "#### 1Ô∏è‚É£ **Working Memory (Short-Term)**\n",
        "\n",
        "* Like human short-term memory\n",
        "* Limited by the **context window** (e.g., 4k, 8k, 32k tokens)\n",
        "* Helps LLM stay coherent in a single conversation\n",
        "\n",
        "---\n",
        "\n",
        "#### 2Ô∏è‚É£ **Long-Term Memory**\n",
        "\n",
        "* Stores info **across sessions**\n",
        "* Techniques:\n",
        "\n",
        "  * External DBs for persistent storage\n",
        "  * Agent-based context management\n",
        "  * **Memory tuning** (injecting fixed facts)\n",
        "\n",
        "---\n",
        "\n",
        "#### 3Ô∏è‚É£ **Memory Management Techniques**\n",
        "\n",
        "* **Context Window Optimization**\n",
        "* **Agents** to track and recall info\n",
        "* **PagedAttention (vLLM)** for better GPU usage\n",
        "\n",
        "---\n",
        "\n",
        "#### 4Ô∏è‚É£ **Key Applications**\n",
        "\n",
        "* ü§ñ **Conversational Memory** ‚Äî Chatbots, Customer Support\n",
        "* üß≠ **Agent Memory** ‚Äî Autonomous agents tracking goals\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQs1vlFRfahp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ Simulated long-term memory store\n",
        "long_term_memory = {}\n",
        "\n",
        "# üß† Function to query OpenAI with short-term + optional memory\n",
        "def query_llm(user_input, conversation_history, memory_summary=None):\n",
        "    messages = []\n",
        "\n",
        "    # Inject memory summary if available\n",
        "    if memory_summary:\n",
        "        messages.append({\"role\": \"system\", \"content\": f\"Here‚Äôs what you already know about the user: {memory_summary}\"})\n",
        "\n",
        "    # Add past conversation history (short-term memory)\n",
        "    messages.extend(conversation_history)\n",
        "\n",
        "    # Add latest user input\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get response\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    reply = response.choices[0].message.content\n",
        "    return reply\n"
      ],
      "metadata": {
        "id": "kO38Xos3bfQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Conversation\n",
        "\n",
        "conversation_history = []\n",
        "\n",
        "# Step 1: User shares favorite food\n",
        "user_input1 = \"My favorite food is sushi.\"\n",
        "response1 = query_llm(user_input1, conversation_history)\n",
        "conversation_history.append({\"role\": \"user\", \"content\": user_input1})\n",
        "conversation_history.append({\"role\": \"assistant\", \"content\": response1})\n",
        "\n",
        "print(response1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqWHn5xPfqGA",
        "outputId": "49e7c5a9-7d28-4251-a9ed-958a16a05851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sushi is a traditional Japanese dish made with vinegared rice, seaweed, and various ingredients such as raw or cooked fish, vegetables, and sauces. It is known for its fresh and delicate flavors, and I love the combination of different textures and flavors in each bite. Sushi is also a healthy option as it is low in calories and high in protein and omega-3 fatty acids. Whether I'm enjoying simple nigiri sushi or elaborate sushi rolls, I always find it to be a delicious and satisfying meal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory[\"favorite_food\"] = \"sushi\""
      ],
      "metadata": {
        "id": "6XrBT4t9fqC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear short-term memory (simulate new session)\n",
        "conversation_history = []\n",
        "\n",
        "# Inject memory summary\n",
        "memory_summary = f\"The user's favorite food is {long_term_memory.get('favorite_food')}.\"\n",
        "\n",
        "# New unrelated prompt\n",
        "user_input2 = \"Can you suggest a dinner plan for me?\"\n",
        "\n",
        "response2 = query_llm(user_input2, conversation_history, memory_summary)\n",
        "conversation_history.append({\"role\": \"user\", \"content\": user_input2})\n",
        "conversation_history.append({\"role\": \"assistant\", \"content\": response2})\n",
        "\n",
        "print(response2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PxwgztvfqAW",
        "outputId": "08d3fddc-8334-430b-e27d-63735e76fa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! How about a sushi dinner plan? You can start with some miso soup or seaweed salad as appetizers. For the main course, you can enjoy a variety of sushi rolls such as California rolls, spicy tuna rolls, and salmon avocado rolls. You can also add some nigiri sushi like salmon, tuna, and eel. To complement the meal, you can have some edamame and green tea. For dessert, you can finish off with some mochi ice cream or green tea ice cream. Enjoy your sushi dinner!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§Ø Hallucination in LLMs\n",
        "\n",
        "### üîç What is Hallucination?\n",
        "\n",
        "LLM hallucination occurs when a language model generates **confident-sounding but factually incorrect or entirely made-up information**.\n",
        "\n",
        "---\n",
        "\n",
        "### üö® Why It Happens:\n",
        "\n",
        "* üîÑ **No real understanding** ‚Äî LLMs generate based on patterns, not truth\n",
        "* üß† **Trained to predict** next words, not verify facts\n",
        "* üìâ **Missing context** or vague prompts\n",
        "* üèóÔ∏è **Lack of access to real-time knowledge** (if not connected to tools or RAG)\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Real-World Examples:\n",
        "\n",
        "#### **1. Inventing People:**\n",
        "\n",
        "**Prompt:** *\"Tell me about Dr. Rajeev Saxena, the Nobel-winning data scientist from India.\"*\n",
        "**LLM Output:** *\"Dr. Rajeev Saxena won the Nobel Prize in 2021 for his work on neural networks.\"*\n",
        "üëâ **Fact:** No such person exists.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Fabricated References:**\n",
        "\n",
        "**Prompt:** *\"Give me citations for AI fairness research.\"*\n",
        "**LLM Output:** *‚ÄúSee Smith et al., 2020, Journal of Ethical AI, Vol. 4(3).‚Äù*\n",
        "üëâ **Fact:** The journal and paper may not exist at all.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Failing at Math:**\n",
        "\n",
        "**Prompt:** *\"What‚Äôs 847 multiplied by 63?\"*\n",
        "**LLM Output:** *\"The answer is 53,421.\"*\n",
        "üëâ **Fact:** It doesn‚Äôt actually calculate; it tries to \"guess\" the answer.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Hallucinated Product Features:**\n",
        "\n",
        "**Prompt:** *\"What features does the iPhone 20 have?\"*\n",
        "**LLM Output:** *\"The iPhone 20 includes a quantum chip and foldable screen.\"*\n",
        "üëâ **Fact:** That product doesn't exist yet.\n",
        "\n",
        "---\n",
        "\n",
        "### üõ°Ô∏è How to Reduce Hallucination:\n",
        "\n",
        "* ‚úÖ Use **RAG (Retrieval-Augmented Generation)**\n",
        "* ‚úÖ Integrate with **external knowledge sources**\n",
        "* ‚úÖ Employ **fact-checking agents**\n",
        "* ‚úÖ Apply **prompt tuning** and **instruction tuning**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "i4u53PtBg14a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorrect Math"
      ],
      "metadata": {
        "id": "Em65QOYLioZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.9,  # Increase randomness\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Learn addition and substraction what is 111 minus 11 after adding 1 to it\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Likely Hallucination:\\n\", response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goPcX5cGfp9Y",
        "outputId": "b28d8657-fb29-4fd8-bbc8-370c7089285d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Likely Hallucination:\n",
            " 111 - 11 = 100\n",
            "\n",
            "When you add 1 to 111, it becomes 112. So, 112 - 11 = 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fabricated Facts"
      ],
      "metadata": {
        "id": "fFcn0eNqiLWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.9,  # Increase randomness\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Can you tell me about the final which was played between India and West Indies 2007 WC\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Likely Hallucination:\\n\", response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rTI8Mo4fp6-",
        "outputId": "84a749f3-560b-4d3c-d30d-225f0a612b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Likely Hallucination:\n",
            " The final of the 2007 ICC Cricket World Cup was played between India and West Indies on April 28, 2007 at the Kensington Oval in Bridgetown, Barbados. \n",
            "\n",
            "India won the toss and elected to bat first. They posted a total of 157 runs for the loss of 5 wickets in their allotted 20 overs. Yuvraj Singh was the star performer for India, scoring 70 runs off just 30 balls.\n",
            "\n",
            "In reply, West Indies struggled to chase down the target due to some excellent bowling by the Indian team. They were restricted to just 98 runs for the loss of 4 wickets in their 20 overs, handing India a comfortable victory by 59 runs.\n",
            "\n",
            "Yuvraj Singh was named the Player of the Match for his brilliant innings with the bat. This victory marked India's first ICC T20 World Cup win and cemented their reputation as a force to be reckoned with in the shortest format of the game.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîß Prompt Tuning in LLMs\n",
        "\n",
        "* üéØ **What is Prompt Tuning?**\n",
        "  A lightweight fine-tuning method where *learnable prompt vectors* are optimized while keeping the LLM frozen.\n",
        "\n",
        "* üß† **LLM Stays Frozen**\n",
        "  Only the prompt embeddings are updated; model weights are not modified.\n",
        "\n",
        "* ‚ö° **Efficient & Fast**\n",
        "  Requires fewer resources and is faster than full fine-tuning.\n",
        "\n",
        "* üß© **Task-Specific Prompts**\n",
        "  Learns prompts tailored for downstream tasks like classification, summarization, etc.\n",
        "\n",
        "* üí° **Soft vs Hard Prompts**\n",
        "\n",
        "  * *Soft prompts:* Learnable vectors\n",
        "  * *Hard prompts:* Manually written text\n",
        "\n",
        "* üìö **Great for Low-Resource Scenarios**\n",
        "  Works well when labeled data is limited.\n",
        "\n",
        "* üîç **Used With Adapter Frameworks**\n",
        "  Commonly used with PEFT libraries (e.g., Hugging Face + LoRA, Prompt-Tuning APIs)\n",
        "\n"
      ],
      "metadata": {
        "id": "tkMZA74GiPAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Load a small model for fast experimentation\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf9HjX6cQyJO",
        "outputId": "f4a1ec86-37b0-4411-c01f-4eb912dbe2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ STEP 3: Load IMDb dataset & sample subset\n",
        "dataset = load_dataset(\"imdb\", split=\"train\").select(range(2000))\n",
        "print(dataset[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I7Arf24YyT1",
        "outputId": "fb68d4fc-abcb-45bf-ac9b-46db4a32bd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.', \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\", \"This film was probably inspired by Godard's Masculin, f√©minin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\", 'Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoked fish hit the U.S. I was too young to get in the theater (although I did manage to sneak into \"Goodbye Columbus\"). Then a screening at a local film museum beckoned - Finally I could see this film, except now I was as old as my parents were when they schlepped to see it!!<br /><br />The ONLY reason this film was not condemned to the anonymous sands of time was because of the obscenity case sparked by its U.S. release. MILLIONS of people flocked to this stinker, thinking they were going to see a sex film...Instead, they got lots of closeups of gnarly, repulsive Swedes, on-street interviews in bland shopping malls, asinie political pretension...and feeble who-cares simulated sex scenes with saggy, pale actors.<br /><br />Cultural icon, holy grail, historic artifact..whatever this thing was, shred it, burn it, then stuff the ashes in a lead box!<br /><br />Elite esthetes still scrape to find value in its boring pseudo revolutionary political spewings..But if it weren\\'t for the censorship scandal, it would have been ignored, then forgotten.<br /><br />Instead, the \"I Am Blank, Blank\" rhythymed title was repeated endlessly for years as a titilation for porno films (I am Curious, Lavender - for gay films, I Am Curious, Black - for blaxploitation films, etc..) and every ten years or so the thing rises from the dead, to be viewed by a new generation of suckers who want to see that \"naughty sex film\" that \"revolutionized the film industry\"...<br /><br />Yeesh, avoid like the plague..Or if you MUST see it - rent the video and fast forward to the \"dirty\" parts, just to get it over with.<br /><br />'], 'label': [0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ STEP 4: Convert to prompt-response format\n",
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"input\": f\"Classify the sentiment: {example['text'][:300]}\",\n",
        "        \"output\": \"positive\" if example[\"label\"] == 1 else \"negative\"\n",
        "    }\n",
        "\n",
        "formatted_dataset = dataset.map(format_prompt)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1a52c998298f4d63b804047864d2f184",
            "30d276c8fdf14ab7a831b51b1d102588",
            "8c19fb87d5894768940924944ec2f45e",
            "f7676891a7ad44a1850be301526a93e3",
            "490ddc81033843ffae29e11252cb6fb9",
            "6691b70ab07042ccbd86366ea819165e",
            "4d062ab984e441f987118322da4f8356",
            "55722fd798db4408a27f3d9debcfb3bf",
            "7264ad68ee284869a92270b15c8ab61a",
            "3451543f2c934398a449e172f8b9aa87",
            "f45c52ae33fc431f9e4e5bc008e5709d"
          ]
        },
        "id": "iiuiSvplY3HG",
        "outputId": "a357568b-e49b-4c96-e30c-91a707147745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a52c998298f4d63b804047864d2f184"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ STEP 5: Tokenize\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    targets = tokenizer(batch[\"output\"], padding=\"max_length\", truncation=True, max_length=10)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = formatted_dataset.map(tokenize_function, remove_columns=formatted_dataset.column_names)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f7a753a333a74b8f92330c94cf9bb0ce",
            "66720a852a254107bb3ed29e52ab9f58",
            "93caec6a66014a3c8cb3147f34e111e9",
            "8a1e9781977a407f92b6a74293552bd3",
            "239a38e751954eef8af02b391f627e84",
            "d95671c4f79c4301a60e67705ddc93a6",
            "0fff679c0dfe476d86ac060d08aacfc9",
            "f097bac04d72439da4477ffacd579281",
            "5388a1cbe86145ae98c78311e4b71172",
            "97ad083d21bc483c9d13b197fa540dd2",
            "0ffccdb54c65468c9be6c469a6f4053b"
          ]
        },
        "id": "A_WCLGVaZF59",
        "outputId": "e8f6115d-2ba4-42fa-abbc-8b7a5bac196a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7a753a333a74b8f92330c94cf9bb0ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ STEP 6: Load base model and apply PEFT config\n",
        "\n",
        "# Load the base sequence-to-sequence language model from Hugging Face Hub\n",
        "# e.g., model_name = \"google/flan-t5-base\" or \"t5-small\"\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Define configuration for PEFT (Prompt Tuning in this case)\n",
        "peft_config = PromptTuningConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,               # Specify this is a sequence-to-sequence task\n",
        "    prompt_tuning_init=PromptTuningInit.TEXT,      # Initialize soft prompts from a text string\n",
        "    prompt_tuning_init_text=\"Classify the sentiment:\",  # Initialization text for virtual prompt tokens\n",
        "    num_virtual_tokens=10,                         # Number of learnable virtual tokens added to the input\n",
        "    tokenizer_name_or_path=model_name              # Use the same tokenizer as the base model\n",
        ")\n",
        "\n",
        "# Apply the PEFT wrapper to the base model using the defined prompt tuning config\n",
        "# This returns a model that adds and trains soft prompt tokens, keeping base model frozen\n",
        "model = get_peft_model(base_model, peft_config)"
      ],
      "metadata": {
        "id": "qr-IV5ZhZF3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ STEP 7: Training\n",
        "\n",
        "# Define training configurations using HuggingFace's TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",                  # Folder to save model checkpoints or logs\n",
        "    per_device_train_batch_size=4,           # Batch size per device (GPU/CPU) during training\n",
        "    num_train_epochs=3,                      # Number of passes through the full dataset\n",
        "    logging_steps=10,                        # Log training loss every 10 steps\n",
        "    save_strategy=\"no\",                      # Don't save model checkpoints during training\n",
        "    report_to=\"none\"                         # Don't report to tools like WandB or TensorBoard\n",
        ")\n",
        "\n",
        "# Create a Trainer object that handles training and evaluation\n",
        "trainer = Trainer(\n",
        "    model=model,                             # The pre-trained or custom model you want to train\n",
        "    args=training_args,                      # Training arguments defined above\n",
        "    train_dataset=tokenized_dataset,         # The tokenized dataset to train on\n",
        "    tokenizer=tokenizer,                     # Tokenizer (helps with padding, decoding, etc.)\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model)  # Handles dynamic padding of inputs\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pNwiyJHuZMKR",
        "outputId": "9dbd188e-2365-46a6-a744-b071d3e29889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-d7db62f3a056>:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 02:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>48.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>47.883600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>46.726600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>47.439400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>47.046500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>47.464100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>48.135500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>46.587400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>47.745900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>46.764500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>47.373300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>46.539800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>46.714900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>47.253700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>47.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>47.622300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>48.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>47.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>45.896800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>47.862100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>48.640800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>46.767600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>48.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>45.590300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>47.613700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>47.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>48.816800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>46.597500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>48.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>48.288600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>47.610800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>47.152500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>48.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>47.304400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>46.927000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>47.840600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>47.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>48.496900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>46.336600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>46.628800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>47.544900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>48.466600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>47.315400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>47.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>46.960500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>48.380100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>48.623900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>46.855000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>47.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>46.821600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>47.339900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>45.484800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>47.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>46.728300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>47.347100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>47.363000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>47.727200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>47.171400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>48.251300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>47.532300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>47.385600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>46.512000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>47.590600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>47.784900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>48.141100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>48.227600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>47.863700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>47.716500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>48.736500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>48.162800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>48.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>47.362000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>48.331200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>47.243900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>46.667500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>47.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>47.501500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>45.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>48.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>49.599000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>45.826400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>46.721900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>48.347200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>47.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>46.781100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>47.901500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>47.042700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>46.755400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>46.515200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>47.118400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>47.914500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>48.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>48.264600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>47.742900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>47.253500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>46.068200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>47.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>48.622900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>47.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>47.352200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>48.890900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>46.887100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>46.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>46.276200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>46.865200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>46.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>47.556100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>46.899400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>47.124700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>47.367700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>47.636300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>48.013800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>46.895400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>47.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>46.627300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>47.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>47.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>47.168600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>47.520700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>47.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>47.498400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>47.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>47.885900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>47.943400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>48.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>47.269800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>46.441900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>46.565100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>46.708300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>46.492400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>48.514800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>47.912500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>46.222900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>48.785900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>47.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>48.605400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>46.679900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>46.765700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>49.259900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>47.058600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>46.404400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>47.782500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>47.965400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>47.585000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>48.289500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>48.208200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>48.410700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>46.046600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>48.124000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>48.045200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=47.43219694010417, metrics={'train_runtime': 125.0524, 'train_samples_per_second': 47.98, 'train_steps_per_second': 11.995, 'total_flos': 557671514112000.0, 'train_loss': 47.43219694010417, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Manually curated strongly polar examples\n",
        "test_examples = [\n",
        "    {\n",
        "        \"text\": \"Not sure but not a good movie guys ,First half is really great and fun to watch but in second half they ruined everything, I was sure that it was a good direction but ruined by actors somehow\",\n",
        "        \"expected\": \"negative\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"Difficult to predict I was going to rate this negatively but overall If I compare every bad with good then it was a good experience in all.\",\n",
        "        \"expected\": \"positive\"\n",
        "    }\n",
        "]\n",
        "\n",
        "def predict_sentiment(model, text):\n",
        "    prompt = f\"Classify the sentiment: {text[:300]}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
        "    output = model.generate(**inputs, max_new_tokens=5)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# ‚úÖ Compare base vs fine-tuned output\n",
        "for example in test_examples:\n",
        "    review = example[\"text\"]\n",
        "    print(\"\\nüìù Review Snippet:\")\n",
        "    print(review[:250].replace(\"\\n\", \" \") + \"...\")\n",
        "\n",
        "    print(\"üéØ Expected:\", example['expected'])\n",
        "    print(\"üì¶ Original Model Prediction:\", predict_sentiment(original_model, review))\n",
        "    print(\"‚úÖ Fine-Tuned Model Prediction:\", predict_sentiment(tuned_model, review))\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B970T31-ZN2q",
        "outputId": "c845043e-3255-49c9-f84e-e736570eae9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Review Snippet:\n",
            "Not sure but not a good movie guys ,First half is really great and fun to watch but in second half they ruined everything, I was sure that it was a good direction but ruined by actors somehow...\n",
            "üéØ Expected: negative\n",
            "üì¶ Original Model Prediction: negative\n",
            "‚úÖ Fine-Tuned Model Prediction: negative\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìù Review Snippet:\n",
            "Difficult to predict I was going to rate this negatively but overall If I compare every bad with good then it was a good experience in all....\n",
            "üéØ Expected: positive\n",
            "üì¶ Original Model Prediction: negative\n",
            "‚úÖ Fine-Tuned Model Prediction: positive\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}