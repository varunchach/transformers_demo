{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20da5ccb"
      },
      "source": [
        "# Task\n",
        "Provide a comprehensive tutorial on fundamental Natural Language Processing (NLP) concepts using the `transformers` library, covering tokenization strategies (basic and subword), word embeddings, model inference (including logits and attention), text generation (step-by-step and using `pipeline`), and practical applications such as semantic similarity and basic hybrid search. The tutorial should also touch upon memory-efficient inference (e.g., quantization) and conclude with a summary and next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ea59efa"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load a tiny, real-world NLP dataset (e.g., a few sentences from the `datasets` library or a custom list of strings) and display its content. Briefly explain 'context length' in this context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64b23a68",
        "outputId": "5e9ec5de-8782-4220-d30b-8cb140ec2e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Texts:\n",
            "1. The quick brown fox jumps over the lazy dog.\n",
            "2. Natural Language Processing is a fascinating field.\n",
            "3. Large language models have revolutionized AI.\n",
            "4. The weather today is sunny with a light breeze.\n",
            "5. Cats are known for their agility and independent nature.\n"
          ]
        }
      ],
      "source": [
        "sample_texts = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Natural Language Processing is a fascinating field.\",\n",
        "    \"Large language models have revolutionized AI.\",\n",
        "    \"The weather today is sunny with a light breeze.\",\n",
        "    \"Cats are known for their agility and independent nature.\"\n",
        "]\n",
        "\n",
        "print(\"Sample Texts:\")\n",
        "for i, text in enumerate(sample_texts):\n",
        "    print(f\"{i+1}. {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa5cdd04"
      },
      "source": [
        "### Understanding Context Length\n",
        "\n",
        "In the realm of Natural Language Processing, especially with models like those in the `transformers` library, **context length** (often referred to as 'maximum sequence length' or 'context window') is a crucial concept. It refers to the maximum number of tokens (words or subword units) that a model can process or attend to at once.\n",
        "\n",
        "For our `sample_texts`:\n",
        "* Each sentence, such as \"The quick brown fox jumps over the lazy dog.\", represents a piece of text that would typically be fed into an NLP model.\n",
        "* When we say a model has a context length, it means it can only 'see' and process a certain number of tokens from such a sentence (or multiple sentences combined) simultaneously.\n",
        "* If a text exceeds the model's context length, it usually needs to be truncated or split, as the model cannot process the entire input at once. In our simple dataset, each sentence is short enough to easily fit within a typical model's context window, serving as a clean, self-contained piece of 'context'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb8e9832"
      },
      "source": [
        "## Basic Tokenization\n",
        "\n",
        "### Subtask:\n",
        "Using a basic tokenizer (e.g., from `transformers`), tokenize a sample sentence from the dataset. Display the resulting tokens and their corresponding token IDs. Explain what 'tokens' are here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92e6bdac",
        "outputId": "630e981d-b852-4c5b-de92-afa489309579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Sentence: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Tokens: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "Token IDs: [101, 1996, 4248, 2829, 4419, 14523, 2058, 1996, 13971, 3899, 1012, 102]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 2. Load a pre-trained tokenizer for a small model\n",
        "basic_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 3. Select the first sentence from the sample_texts list\n",
        "sample_sentence = sample_texts[0]\n",
        "print(f\"\\nSample Sentence: {sample_sentence}\\n\")\n",
        "\n",
        "# 4. Tokenize the selected sample sentence\n",
        "tokens = basic_tokenizer.tokenize(sample_sentence)\n",
        "\n",
        "# 5. Print the original tokens\n",
        "print(f\"Tokens: {tokens}\")\n",
        "\n",
        "# 6. Print the corresponding token IDs\n",
        "token_ids = basic_tokenizer(sample_sentence)['input_ids']\n",
        "print(f\"Token IDs: {token_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f55b330"
      },
      "source": [
        "### What are 'Tokens'?\n",
        "\n",
        "In Natural Language Processing (NLP), **tokens** are the fundamental units into which a piece of text is broken down for processing by a model. This process is called **tokenization**.\n",
        "\n",
        "Tokens can vary depending on the tokenization strategy:\n",
        "\n",
        "*   **Words**: In simpler tokenization, tokens might be individual words, like \"The\", \"quick\", \"brown\", etc.\n",
        "*   **Subword Units**: More commonly in modern NLP (especially with models like BERT, which `bert-base-uncased` tokenizer uses), tokens are subword units. This means words can be broken down into smaller, meaningful pieces. For example, \"tokenization\" might be broken into \"token\", \"##iza\", \"##tion\". This approach helps handle out-of-vocabulary words and reduces the vocabulary size.\n",
        "*   **Punctuation**: Punctuation marks (like '.', '?', '!') are often treated as separate tokens.\n",
        "*   **Special Tokens**: Models also use special tokens for various purposes, such as:\n",
        "    *   `[CLS]` (Classifier token): Often used at the beginning of a sequence for classification tasks.\n",
        "    *   `[SEP]` (Separator token): Used to separate different segments of text, or mark the end of a single sequence.\n",
        "    *   `[PAD]` (Padding token): Used to make sequences of varying lengths uniform for batch processing.\n",
        "\n",
        "Each unique token is assigned a numerical **token ID** by the tokenizer's vocabulary. These IDs are what the NLP models actually process, rather than the raw text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65265260"
      },
      "source": [
        "## Subword Tokenization Comparison\n",
        "\n",
        "### Subtask:\n",
        "Introduce subword tokenization. Apply a subword tokenizer (e.g., WordPiece or SentencePiece) to the same sample sentence and visually compare its output (tokens and IDs) with the basic tokenization from the previous step to highlight differences and benefits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed425bc8"
      },
      "source": [
        "### What are 'Subword Tokens'?\n",
        "\n",
        "Unlike basic tokenization which often splits text strictly by words or punctuation, **subword tokenization** breaks down words into smaller, frequently occurring units (subwords). This approach offers significant advantages in modern NLP:\n",
        "\n",
        "*   **Handling Out-of-Vocabulary (OOV) Words**: If a model encounters a word it hasn't seen during training, subword tokenization can break it down into known subwords. For example, 'unbelievable' might be split into 'un', 'believe', and 'able', all of which are common and likely in the vocabulary, even if 'unbelievable' itself is not.\n",
        "*   **Reduced Vocabulary Size**: Instead of needing to store every possible word, the model only needs a vocabulary of common subwords, significantly reducing the overall vocabulary size while still being able to represent a vast number of words.\n",
        "*   **Semantic Meaning**: Subwords often carry semantic meaning (e.g., prefixes like 'un-', suffixes like '-tion'), which can help the model understand new words or nuances.\n",
        "*   **Efficiency**: Smaller vocabulary sizes and better handling of rare words contribute to more efficient model training and inference.\n",
        "\n",
        "Popular subword tokenization algorithms include:\n",
        "\n",
        "*   **WordPiece**: Used by models like BERT, DistilBERT.\n",
        "*   **SentencePiece**: Used by models like T5, XLNet, ALBERT.\n",
        "*   **BPE (Byte Pair Encoding)**: Used by models like GPT-2, RoBERTa.\n",
        "\n",
        "In this step, we will use a tokenizer that employs a subword strategy (e.g., SentencePiece, as used by `t5-small`) to demonstrate these differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59d2456b",
        "outputId": "02c18152-8af7-4b36-f7c7-6e1e98311df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Sentence: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "--- Basic Tokenization (bert-base-uncased) ---\n",
            "Tokens: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "Token IDs: [101, 1996, 4248, 2829, 4419, 14523, 2058, 1996, 13971, 3899, 1012, 102]\n",
            "\n",
            "--- Subword Tokenization (t5-small, SentencePiece) ---\n",
            "Tokens: ['▁The', '▁quick', '▁brown', '▁', 'fox', '▁jump', 's', '▁over', '▁the', '▁lazy', '▁dog', '.']\n",
            "Token IDs: [37, 1704, 4216, 3, 20400, 4418, 7, 147, 8, 19743, 1782, 5, 1]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 2. Load a pre-trained subword tokenizer (e.g., t5-small uses SentencePiece)\n",
        "subword_tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# 3. Tokenize the sample sentence using the subword tokenizer\n",
        "subword_tokens = subword_tokenizer.tokenize(sample_sentence)\n",
        "\n",
        "# 4. Encode the sample sentence using the subword tokenizer to get input_ids\n",
        "subword_token_ids = subword_tokenizer(sample_sentence)['input_ids']\n",
        "\n",
        "# 5. Print the sample sentence\n",
        "print(f\"\\nSample Sentence: {sample_sentence}\\n\")\n",
        "\n",
        "# 6. Print the basic tokenization results for comparison\n",
        "print(\"--- Basic Tokenization (bert-base-uncased) ---\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Token IDs: {token_ids}\")\n",
        "\n",
        "# 7. Print the subword tokenization results for comparison\n",
        "print(\"\\n--- Subword Tokenization (t5-small, SentencePiece) ---\")\n",
        "print(f\"Tokens: {subword_tokens}\")\n",
        "print(f\"Token IDs: {subword_token_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1fe68fd"
      },
      "source": [
        "## Generate Embeddings\n",
        "\n",
        "### Subtask:\n",
        "Convert token IDs into dense vector representations (embeddings) using a pre-trained model's embedding layer. Display the shapes of the generated embeddings and show a few sample numerical values. Create a simple visualization (e.g., a bar chart of embedding values for a single token) to intuitively show what embeddings represent. Explain 'embeddings' here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "0d894827",
        "outputId": "7147de29-6a5a-41fb-ca9e-c81354c9ddde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized input IDs shape: torch.Size([1, 13])\n",
            "Tokenized input IDs: tensor([[   37,  1704,  4216,     3, 20400,  4418,     7,   147,     8, 19743,\n",
            "          1782,     5,     1]])\n",
            "\n",
            "Embeddings shape: torch.Size([1, 13, 512])\n",
            "\n",
            "Sample numerical values for the embedding of the first token (first 10 dimensions):\n",
            "[ 0.0508669   0.09412619 -0.07092512 -0.10859732  0.07759151 -0.07677786\n",
            " -0.28492472  0.06728212 -0.03779788  0.07893212]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import T5EncoderModel # Changed from AutoModel to T5EncoderModel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load a pre-trained T5 Encoder Model (e.g., t5-small)\n",
        "# This model will be used to generate embeddings. We load T5EncoderModel for encoder-only output.\n",
        "model = T5EncoderModel.from_pretrained('t5-small')\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 2. Tokenize the sample sentence using the subword_tokenizer and convert to PyTorch tensor\n",
        "# The subword_tokenizer was previously loaded as 't5-small'.\n",
        "# We need to add batch dimension as models typically expect batched inputs.\n",
        "# Also, include attention_mask for proper processing with padding and truncation.\n",
        "inputs = subword_tokenizer(sample_sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "input_ids = inputs['input_ids']\n",
        "attention_mask = inputs['attention_mask']\n",
        "\n",
        "print(f\"Tokenized input IDs shape: {input_ids.shape}\")\n",
        "print(f\"Tokenized input IDs: {input_ids}\")\n",
        "\n",
        "# 3. Pass the tokenized input through the loaded model to obtain the model's outputs\n",
        "with torch.no_grad(): # Disable gradient calculation for inference\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# 4. Extract the embeddings (last_hidden_state)\n",
        "# For T5EncoderModel, last_hidden_state directly contains the contextualized embeddings for each token.\n",
        "embeddings = outputs.last_hidden_state\n",
        "\n",
        "print(f\"\\nEmbeddings shape: {embeddings.shape}\")\n",
        "\n",
        "# 5. Print a small slice of the embeddings (e.g., the first token's embedding)\n",
        "print(\"\\nSample numerical values for the embedding of the first token (first 10 dimensions):\")\n",
        "# Access the embedding for the first token in the batch (index 0) and the first token in the sequence (index 0)\n",
        "print(embeddings[0, 0, :10].numpy())\n",
        "\n",
        "# 6. Create a simple visualization (e.g., a bar chart of embedding values for a single token)\n",
        "# Select the embedding for the first token\n",
        "first_token_embedding = embeddings[0, 0, :].squeeze().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(first_token_embedding)), first_token_embedding)\n",
        "plt.xlabel('Dimension')\n",
        "plt.ylabel('Value')\n",
        "plt.title(f'Embedding Values for the First Token (ID: {input_ids[0, 0]}, Token: \"{subword_tokenizer.decode(input_ids[0, 0])}\")')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381c1531"
      },
      "source": [
        "### What are 'Embeddings'?\n",
        "\n",
        "In Natural Language Processing (NLP), **embeddings** are dense, real-valued vector representations of words, subwords, or entire pieces of text. Unlike sparse representations (like one-hot encodings) which can be very high-dimensional and don't capture semantic relationships, embeddings are designed to capture the semantic and syntactic meaning of words and their relationships in a continuous vector space.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "*   **Dense Vectors**: Instead of zeros and ones, each dimension in an embedding vector holds a real number. These numbers are learned during the training of large language models.\n",
        "*   **Semantic Meaning**: Words that are semantically similar (e.g., \"king\" and \"queen\", or \"dog\" and \"cat\") will have embedding vectors that are close to each other in this vector space. Conversely, dissimilar words will be far apart.\n",
        "*   **Contextualization**: Modern NLP models, particularly transformer-based models like T5 (which we used), generate *contextualized embeddings*. This means that the embedding for a word like \"bank\" will be different depending on whether it appears in \"river bank\" or \"financial bank\". The model considers the surrounding words to create a representation that reflects the word's meaning in that specific context.\n",
        "*   **How they are learned**: Embeddings are typically learned as part of a larger neural network training process. The model adjusts the embedding values to optimize a specific task (e.g., predicting the next word, translation, classification). Through this process, the model learns to encode rich linguistic information into these vectors.\n",
        "*   **Purpose**: Embeddings serve as the input to subsequent layers in a neural network, allowing the model to work with numerical representations that capture meaning. They are crucial for tasks like semantic similarity, classification, translation, and question answering, as they provide a foundational understanding of the text's content.\n",
        "\n",
        "The visualization you saw for the first token's embedding (e.g., `[0.05, 0.09, -0.07, ...]`) represents these numerical values. Each number in the vector corresponds to a dimension in the embedding space, and the combination of these values forms a unique 'fingerprint' for that token in its context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855d5b60"
      },
      "source": [
        "## Calculate Semantic Similarity\n",
        "\n",
        "### Subtask:\n",
        "Compute sentence embeddings for a few sample sentences. Calculate their cosine similarity to demonstrate semantic relatedness. Display the similarity scores, possibly using a small heatmap or matrix visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-kQctCBbInm",
        "outputId": "2adfecea-5b59-4355-90a5-c0a2c4b6a2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity Matrix:\n",
            "            Sentence 1  Sentence 2  Sentence 3  Sentence 4  Sentence 5\n",
            "Sentence 1    1.000000    0.478483    0.476504    0.618914    0.566981\n",
            "Sentence 2    0.478483    1.000000    0.665145    0.613217    0.604374\n",
            "Sentence 3    0.476504    0.665145    1.000000    0.513983    0.577336\n",
            "Sentence 4    0.618914    0.613217    0.513983    1.000000    0.578964\n",
            "Sentence 5    0.566981    0.604374    0.577336    0.578964    1.000000\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Define a function to get sentence embeddings\n",
        "def get_sentence_embedding(text):\n",
        "    inputs = subword_tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get last hidden state (batch_size, sequence_length, hidden_size)\n",
        "    last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "    # To get a single sentence embedding, average the last_hidden_state\n",
        "    # along the sequence dimension, considering the attention_mask.\n",
        "    # Expand attention_mask to match hidden_state dimensions for element-wise multiplication\n",
        "    expanded_attention_mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "\n",
        "    # Sum the masked embeddings and divide by the sum of the mask (effective sequence length)\n",
        "    sum_embeddings = torch.sum(last_hidden_state * expanded_attention_mask, 1)\n",
        "    sum_mask = torch.clamp(expanded_attention_mask.sum(1), min=1e-9) # Avoid division by zero\n",
        "    sentence_embedding = sum_embeddings / sum_mask\n",
        "\n",
        "    return sentence_embedding.squeeze(0) # Remove batch dimension if it was 1\n",
        "\n",
        "# 4. Call this function for each sentence in sample_texts to get a list of sentence embeddings.\n",
        "sentence_embeddings = [get_sentence_embedding(text) for text in sample_texts]\n",
        "\n",
        "# 6. Initialize an empty matrix or list to store cosine similarity scores.\n",
        "num_sentences = len(sample_texts)\n",
        "similarity_matrix = torch.zeros((num_sentences, num_sentences))\n",
        "\n",
        "# 7. Iterate through all unique pairs of sentence embeddings and calculate cosine similarity.\n",
        "for i in range(num_sentences):\n",
        "    for j in range(num_sentences):\n",
        "        # F.cosine_similarity expects 1D inputs for single vectors, or 2D inputs where rows are vectors\n",
        "        similarity = F.cosine_similarity(sentence_embeddings[i], sentence_embeddings[j], dim=0)\n",
        "        similarity_matrix[i, j] = similarity\n",
        "\n",
        "# 8. Store the calculated similarity scores in a readable format (Pandas DataFrame).\n",
        "similarity_df = pd.DataFrame(similarity_matrix.numpy(),\n",
        "                             index=[f\"Sentence {k+1}\" for k in range(num_sentences)],\n",
        "                             columns=[f\"Sentence {k+1}\" for k in range(num_sentences)])\n",
        "\n",
        "print(\"Cosine Similarity Matrix:\")\n",
        "print(similarity_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ee529549",
        "outputId": "8c23e541-502d-44d1-dbd2-c5dcb966a132"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 10. Create a heatmap using seaborn.heatmap() to visualize the similarity matrix.\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(similarity_df, annot=True, cmap='viridis', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Cosine Similarity Heatmap of Sample Sentences')\n",
        "plt.xlabel('Compared Sentence')\n",
        "plt.ylabel('Source Sentence')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8810450f"
      },
      "source": [
        "## Model Forward Pass\n",
        "\n",
        "### Subtask:\n",
        "Load a small, pre-trained Transformer model (e.g., a DistilBERT variant). Pass tokenized input from a sample sentence through the model and display the shapes of the model's output (e.g., last hidden state, logits). Briefly explain 'inference' and mention the role of 'attention' in Transformers during this step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10f1ca52",
        "outputId": "8ae3e03e-b1f8-4b50-d65e-f203077a517e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Sentence for Inference: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Shape of last_hidden_state: torch.Size([1, 12, 768])\n",
            "Shape of logits: torch.Size([1, 2])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# 1. Load a pre-trained Transformer model for sequence classification\n",
        "#    Choosing 'distilbert-base-uncased' for efficiency and clear output with logits.\n",
        "model_inference = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model_inference.eval() # Set model to evaluation mode\n",
        "\n",
        "# 2. Load a corresponding tokenizer for the chosen model\n",
        "tokenizer_inference = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# 3. Select a sample sentence from the sample_texts list\n",
        "sample_sentence_inference = sample_texts[0]\n",
        "print(f\"\\nSample Sentence for Inference: {sample_sentence_inference}\\n\")\n",
        "\n",
        "# 4. Tokenize the sample sentence, ensuring return_tensors='pt'\n",
        "inputs_inference = tokenizer_inference(sample_sentence_inference, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "# 5. Pass the tokenized input through the model within a torch.no_grad() context\n",
        "with torch.no_grad():\n",
        "    outputs_inference = model_inference(**inputs_inference, output_hidden_states=True)\n",
        "\n",
        "# 6. Display the shape of the model's last_hidden_state\n",
        "# For DistilBERT, last_hidden_state is directly available.\n",
        "last_hidden_state_shape = outputs_inference.hidden_states[-1].shape\n",
        "print(f\"Shape of last_hidden_state: {last_hidden_state_shape}\")\n",
        "\n",
        "# 7. Display the shape of the model's logits\n",
        "logits_shape = outputs_inference.logits.shape\n",
        "print(f\"Shape of logits: {logits_shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32a11987",
        "outputId": "511f0f79-6c48-40d6-f960-4a6bf8902dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Sentence for Logits and Prediction: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Shape of raw logits: torch.Size([1, 10, 50257])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 1 & 2. Load a pre-trained generative Transformer model (gpt2) and its corresponding tokenizer.\n",
        "model_generative = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "tokenizer_generative = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# 3. Set the model to evaluation mode\n",
        "model_generative.eval()\n",
        "\n",
        "# 4. Take a sample sentence from earlier steps\n",
        "# The variable 'sample_sentence' is available from previous executed cells.\n",
        "print(f\"\\nSample Sentence for Logits and Prediction: {sample_sentence}\\n\")\n",
        "\n",
        "# 5. Tokenize the sample_sentence, ensuring return_tensors='pt'\n",
        "inputs_generative = tokenizer_generative(sample_sentence, return_tensors='pt')\n",
        "\n",
        "# 6. Pass the tokenized input through the model within a torch.no_grad() context\n",
        "with torch.no_grad():\n",
        "    outputs_generative = model_generative(**inputs_generative)\n",
        "\n",
        "# 7. Extract the logits from the model outputs. Display their shape.\n",
        "# For CausalLM models, the output usually includes 'logits' directly.\n",
        "logits = outputs_generative.logits\n",
        "print(f\"Shape of raw logits: {logits.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d0d1941"
      },
      "source": [
        "### What are 'Logits'?\n",
        "\n",
        "In the context of a generative language model like GPT-2, **logits** are the raw, unnormalized prediction scores produced by the model's final layer. For each position in the input sequence, and for each possible token in the model's vocabulary, the model outputs a logit value.\n",
        "\n",
        "Think of logits as confidence scores:\n",
        "*   A higher logit value for a particular token indicates that the model is more confident that this token should be the next one in the sequence at that position.\n",
        "*   These values are 'raw' because they have not yet been transformed into probabilities. They can range from negative infinity to positive infinity.\n",
        "\n",
        "Specifically, for next token prediction in a causal language model, the logits for the *last position* in the input sequence are of particular interest. These logits represent the model's prediction for the very next token that should follow the entire input sequence provided. To convert these logits into actual probabilities (a distribution over the entire vocabulary where all values are between 0 and 1 and sum to 1), a **softmax** function is applied. This allows us to determine the most probable next tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b617bf43",
        "outputId": "a36e2499-b300-45a7-e704-b738b852178c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of last token's logits: torch.Size([50257])\n",
            "Shape of probabilities: torch.Size([50257])\n",
            "\n",
            "Top 5 most probable next tokens and their probabilities:\n",
            "Token: '\n",
            "' (ID: 198), Probability: 0.2552\n",
            "Token: ' The' (ID: 383), Probability: 0.1290\n",
            "Token: ' \"' (ID: 366), Probability: 0.1206\n",
            "Token: ' He' (ID: 679), Probability: 0.0837\n",
            "Token: ' It' (ID: 632), Probability: 0.0404\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# 9. Select the logits corresponding to the *last* token in the input sequence\n",
        "# The logits shape is [batch_size, sequence_length, vocab_size]\n",
        "# We need logits[0, -1, :] for the last token's predictions in the first (and only) batch item.\n",
        "last_token_logits = logits[0, -1, :]\n",
        "print(f\"Shape of last token's logits: {last_token_logits.shape}\")\n",
        "\n",
        "# 10. Convert these last token logits into probabilities using torch.nn.functional.softmax\n",
        "probabilities = F.softmax(last_token_logits, dim=-1)\n",
        "print(f\"Shape of probabilities: {probabilities.shape}\")\n",
        "\n",
        "# 11. Use torch.topk to find the top-k (e.g., top 5) most probable next token IDs and their probabilities.\n",
        "top_k = 5\n",
        "top_k_probabilities, top_k_token_ids = torch.topk(probabilities, top_k)\n",
        "\n",
        "print(f\"\\nTop {top_k} most probable next tokens and their probabilities:\")\n",
        "for i in range(top_k):\n",
        "    token_id = top_k_token_ids[i].item()\n",
        "    prob = top_k_probabilities[i].item()\n",
        "    decoded_token = tokenizer_generative.decode(token_id)\n",
        "    print(f\"Token: '{decoded_token}' (ID: {token_id}), Probability: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "806d4095"
      },
      "source": [
        "## Step-by-Step Text Generation\n",
        "\n",
        "### Subtask:\n",
        "Demonstrate a simplified, step-by-step text generation process (e.g., using greedy decoding). Show how the model iteratively predicts the next token based on the current sequence, building up the generated text one token at a time. Provide brief explanations at each step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fc2ada0",
        "outputId": "7311a5c2-108c-440a-ce4a-90eb6045b807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Prompt: 'The quick brown fox'\n",
            "\n",
            "---- Step-by-Step Generation ----\n",
            "\n",
            "--- Generation Step 1 ---\n",
            "Current Sequence: 'The quick brown foxes'\n",
            "Predicted Token ID: 274, Decoded: 'es'\n",
            "\n",
            "--- Generation Step 2 ---\n",
            "Current Sequence: 'The quick brown foxes are'\n",
            "Predicted Token ID: 389, Decoded: ' are'\n",
            "\n",
            "--- Generation Step 3 ---\n",
            "Current Sequence: 'The quick brown foxes are a'\n",
            "Predicted Token ID: 257, Decoded: ' a'\n",
            "\n",
            "--- Generation Step 4 ---\n",
            "Current Sequence: 'The quick brown foxes are a great'\n",
            "Predicted Token ID: 1049, Decoded: ' great'\n",
            "\n",
            "--- Generation Step 5 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way'\n",
            "Predicted Token ID: 835, Decoded: ' way'\n",
            "\n",
            "--- Generation Step 6 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to'\n",
            "Predicted Token ID: 284, Decoded: ' to'\n",
            "\n",
            "--- Generation Step 7 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get'\n",
            "Predicted Token ID: 651, Decoded: ' get'\n",
            "\n",
            "--- Generation Step 8 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a'\n",
            "Predicted Token ID: 257, Decoded: ' a'\n",
            "\n",
            "--- Generation Step 9 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little'\n",
            "Predicted Token ID: 1310, Decoded: ' little'\n",
            "\n",
            "--- Generation Step 10 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit'\n",
            "Predicted Token ID: 1643, Decoded: ' bit'\n",
            "\n",
            "--- Generation Step 11 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of'\n",
            "Predicted Token ID: 286, Decoded: ' of'\n",
            "\n",
            "--- Generation Step 12 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a'\n",
            "Predicted Token ID: 257, Decoded: ' a'\n",
            "\n",
            "--- Generation Step 13 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick'\n",
            "Predicted Token ID: 4829, Decoded: ' kick'\n",
            "\n",
            "--- Generation Step 14 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out'\n",
            "Predicted Token ID: 503, Decoded: ' out'\n",
            "\n",
            "--- Generation Step 15 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out of'\n",
            "Predicted Token ID: 286, Decoded: ' of'\n",
            "\n",
            "--- Generation Step 16 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out of your'\n",
            "Predicted Token ID: 534, Decoded: ' your'\n",
            "\n",
            "--- Generation Step 17 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out of your dog'\n",
            "Predicted Token ID: 3290, Decoded: ' dog'\n",
            "\n",
            "--- Generation Step 18 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out of your dog.'\n",
            "Predicted Token ID: 13, Decoded: '.'\n",
            "\n",
            "--- Generation Step 19 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out of your dog.\n",
            "'\n",
            "Predicted Token ID: 198, Decoded: '\n",
            "'\n",
            "\n",
            "--- Generation Step 20 ---\n",
            "Current Sequence: 'The quick brown foxes are a great way to get a little bit of a kick out of your dog.\n",
            "\n",
            "'\n",
            "Predicted Token ID: 198, Decoded: '\n",
            "'\n",
            "\n",
            "---- Final Generated Text ----\n",
            "'The quick brown foxes are a great way to get a little bit of a kick out of your dog.\n",
            "\n",
            "'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1. Define a starting prompt string\n",
        "prompt_text = \"The quick brown fox\"\n",
        "print(f\"\\nStarting Prompt: '{prompt_text}'\\n\")\n",
        "\n",
        "# 2. Define a maximum number of tokens to generate\n",
        "max_new_tokens = 20 # Max tokens to generate *after* the prompt\n",
        "\n",
        "# Tokenize the initial prompt\n",
        "input_ids = tokenizer_generative.encode(prompt_text, return_tensors='pt')\n",
        "\n",
        "# Initialize an empty list to store the generated token IDs\n",
        "generated_token_ids = []\n",
        "\n",
        "print(\"---- Step-by-Step Generation ----\")\n",
        "\n",
        "# 4. Enter a loop that continues until the maximum length is reached or an end-of-sequence token is predicted\n",
        "for i in range(max_new_tokens):\n",
        "    print(f\"\\n--- Generation Step {i+1} ---\")\n",
        "\n",
        "    # a. Tokenize the current sequence (prompt + previously generated tokens)\n",
        "    # The input_ids already contain the current sequence\n",
        "\n",
        "    # b. Pass the tokenized input through the model within a torch.no_grad() context\n",
        "    with torch.no_grad():\n",
        "        outputs = model_generative(input_ids)\n",
        "\n",
        "    # c. Extract the logits for the *last* token in the sequence\n",
        "    # The shape is [batch_size, sequence_length, vocab_size]\n",
        "    last_token_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "    # d. Predict the next token using greedy decoding: select the token with the highest logit score\n",
        "    predicted_token_id = torch.argmax(last_token_logits, dim=-1)\n",
        "\n",
        "    # e. Append the predicted token ID to your list of generated tokens\n",
        "    generated_token_ids.append(predicted_token_id.item())\n",
        "\n",
        "    # Append the predicted token to the input_ids for the next iteration\n",
        "    input_ids = torch.cat([input_ids, predicted_token_id.unsqueeze(0)], dim=-1)\n",
        "\n",
        "    # f. Decode the current full sequence of token IDs (initial prompt + generated tokens) back into a string\n",
        "    current_generated_text = tokenizer_generative.decode(input_ids[0], skip_special_tokens=True)\n",
        "    print(f\"Current Sequence: '{current_generated_text}'\")\n",
        "    print(f\"Predicted Token ID: {predicted_token_id.item()}, Decoded: '{tokenizer_generative.decode(predicted_token_id.item())}'\")\n",
        "\n",
        "    # g. If the predicted token is an end-of-sequence token, break the loop.\n",
        "    # For GPT-2, the EOS token is typically tokenizer.eos_token_id (50256).\n",
        "    if predicted_token_id == tokenizer_generative.eos_token_id:\n",
        "        print(\"End-of-sequence token detected, stopping generation.\")\n",
        "        break\n",
        "\n",
        "# 5. After the loop, print the final generated text.\n",
        "final_generated_text = tokenizer_generative.decode(input_ids[0], skip_special_tokens=True)\n",
        "print(f\"\\n---- Final Generated Text ----\")\n",
        "print(f\"'{final_generated_text}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "536a7dbf"
      },
      "source": [
        "### What is Step-by-Step Text Generation (Greedy Decoding)?\n",
        "\n",
        "**Text generation** is the process of creating new sequences of text that are coherent and contextually relevant to a given prompt. When we perform it \"step-by-step,\" we mean the model predicts one token at a time, adds it to the current sequence, and then uses this new, longer sequence to predict the *next* token.\n",
        "\n",
        "**Greedy decoding** is the simplest strategy for this iterative process. At each step, after the model computes the logits (raw scores) for all possible next tokens in its vocabulary, it simply selects the token with the *highest probability* (the highest logit after a softmax transformation) as the next word. This chosen token is then appended to the input sequence, and the process repeats until a specified maximum length is reached or the model generates an end-of-sequence (EOS) token.\n",
        "\n",
        "Let's break down the process demonstrated in the code:\n",
        "\n",
        "1.  **Initial Prompt**: We start with an input text (e.g., \"The quick brown fox\"). This text is tokenized into numerical IDs.\n",
        "2.  **Model Prediction**: These token IDs are fed into the generative language model (like GPT-2). The model processes this sequence and outputs logits for every possible next token in its vocabulary.\n",
        "3.  **Greedy Choice**: From these logits, we find the token with the highest logit value. This is the model's single most confident prediction for what should come next.\n",
        "4.  **Append and Repeat**: The predicted token's ID is then added to our current sequence of token IDs. This new, extended sequence becomes the input for the next prediction step.\n",
        "5.  **Termination**: The loop continues, adding one token at a time, until either a predefined `max_new_tokens` limit is reached or the model explicitly generates a special \"end-of-sequence\" token, signaling that it has completed its generation.\n",
        "\n",
        "While simple and efficient, greedy decoding can sometimes lead to suboptimal or repetitive text because it always takes the locally best option, potentially missing a better sequence that might emerge from a less probable early token choice. More advanced generation strategies (like beam search or sampling methods) exist to mitigate this, but greedy decoding clearly illustrates the fundamental token-by-token generation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67a8a341"
      },
      "source": [
        "## Low-level API Demo\n",
        "\n",
        "### Subtask:\n",
        "Show the standard, low-level `transformers` API usage by demonstrating text generation using the model's `.generate()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86893d32",
        "outputId": "29edc18b-adcc-41aa-e7f2-b46cad5fd99e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Prompt for .generate(): 'The weather today is'\n",
            "\n",
            "---- Text Generated using .generate() method ----\n",
            "Original Prompt: 'The weather today is'\n",
            "Generated Text: 'The weather today is very nice and the sun is shining.\n",
            "\n",
            "In fact, it's just a couple of hours before the sun goes down and the clouds come out.\n",
            "\n",
            "I'm sure all of you will be able to find a place to go today,'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1. Define a prompt_text for text generation\n",
        "prompt_text_generate = \"The weather today is\"\n",
        "print(f\"\\nStarting Prompt for .generate(): '{prompt_text_generate}'\\n\")\n",
        "\n",
        "# 2. Tokenize the prompt_text using tokenizer_generative (from previous steps)\n",
        "input_ids_generate = tokenizer_generative.encode(prompt_text_generate, return_tensors='pt')\n",
        "\n",
        "# 3. Call the model_generative.generate() method with the input_ids\n",
        "# 4. Specify max_new_tokens (e.g., 50) and do_sample=True for more varied output\n",
        "#    Optionally, set temperature for controlling randomness.\n",
        "#    num_return_sequences can generate multiple outputs.\n",
        "output_ids_generate = model_generative.generate(\n",
        "    input_ids_generate,\n",
        "    max_new_tokens=50,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer_generative.eos_token_id # Important for generation with padding\n",
        ")\n",
        "\n",
        "# 5. Decode the output_ids back into a human-readable string\n",
        "generated_text_full = tokenizer_generative.decode(output_ids_generate[0], skip_special_tokens=True)\n",
        "\n",
        "# 6. Print the original prompt_text and the generated_text\n",
        "print(\"---- Text Generated using .generate() method ----\")\n",
        "print(f\"Original Prompt: '{prompt_text_generate}'\")\n",
        "print(f\"Generated Text: '{generated_text_full}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34fcf1c9",
        "outputId": "f2fa292d-76a7-4530-a232-ad41b52f6967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Prompt for .generate(): 'The weather today is'\n",
            "\n",
            "---- Text Generated using .generate() method ----\n",
            "Original Prompt: 'The weather today is'\n",
            "Generated Text: 'The weather today is in good condition and we will be back tomorrow afternoon.\n",
            "\n",
            "\"We will be back tomorrow afternoon.\n",
            "\n",
            "\"We will be back today.\"\n",
            "\n",
            "The club has been without its manager since the end of May and a deal has been agreed'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1. Define a prompt_text for text generation\n",
        "prompt_text_generate = \"The weather today is\"\n",
        "print(f\"\\nStarting Prompt for .generate(): '{prompt_text_generate}'\\n\")\n",
        "\n",
        "# 2. Tokenize the prompt_text using tokenizer_generative (from previous steps)\n",
        "#    Modified to return both input_ids and attention_mask\n",
        "inputs_generate = tokenizer_generative(prompt_text_generate, return_tensors='pt')\n",
        "input_ids_generate = inputs_generate['input_ids']\n",
        "attention_mask_generate = inputs_generate['attention_mask']\n",
        "\n",
        "# 3. Call the model_generative.generate() method with the input_ids and attention_mask\n",
        "# 4. Specify max_new_tokens (e.g., 50) and do_sample=True for more varied output\n",
        "#    Optionally, set temperature for controlling randomness.\n",
        "#    num_return_sequences can generate multiple outputs.\n",
        "output_ids_generate = model_generative.generate(\n",
        "    input_ids_generate,\n",
        "    attention_mask=attention_mask_generate, # Pass the attention mask\n",
        "    max_new_tokens=50,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer_generative.eos_token_id # Important for generation with padding\n",
        ")\n",
        "\n",
        "# 5. Decode the output_ids back into a human-readable string\n",
        "generated_text_full = tokenizer_generative.decode(output_ids_generate[0], skip_special_tokens=True)\n",
        "\n",
        "# 6. Print the original prompt_text and the generated_text\n",
        "print(\"---- Text Generated using .generate() method ----\")\n",
        "print(f\"Original Prompt: '{prompt_text_generate}'\")\n",
        "print(f\"Generated Text: '{generated_text_full}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eae61724"
      },
      "source": [
        "## High-level Pipeline Demo\n",
        "\n",
        "### Subtask:\n",
        "Introduce and demonstrate the `transformers` `pipeline` API for a common task (e.g., text generation, classification). Compare its simplified usage and output with the low-level API demonstrated previously.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "03b613ce"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "400d20ee",
        "outputId": "29367823-4cdf-4743-e96c-4b8aec02bd21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Prompt for pipeline: 'The weather today is'\n",
            "\n",
            "---- Text Generated using pipeline API ----\n",
            "Original Prompt: 'The weather today is'\n",
            "Generated Text: 'The weather today is good and the snow is falling on our southern beaches. I'm hoping we'll have some sunshine soon.\"\n",
            "\n",
            "This is the first time in the past year the Storm has been in the South of England.\n",
            "\n",
            "Northern Ireland's Queen's Park'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 2. Create a text generation pipeline\n",
        "# Using the same model and tokenizer ('gpt2') for consistency with previous steps\n",
        "pipeline_generator = pipeline('text-generation', model='gpt2', tokenizer='gpt2')\n",
        "\n",
        "# 3. Define a prompt string for text generation\n",
        "prompt_text_pipeline = \"The weather today is\"\n",
        "print(f\"\\nStarting Prompt for pipeline: '{prompt_text_pipeline}'\\n\")\n",
        "\n",
        "# 4. Call the created pipeline with the prompt string and specify generation parameters\n",
        "pipeline_outputs = pipeline_generator(\n",
        "    prompt_text_pipeline,\n",
        "    max_new_tokens=50,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "# 5. Print the original prompt and the text generated by the pipeline\n",
        "print(\"---- Text Generated using pipeline API ----\")\n",
        "print(f\"Original Prompt: '{prompt_text_pipeline}'\")\n",
        "# The pipeline returns a list of dictionaries, extract the generated_text\n",
        "print(f\"Generated Text: '{pipeline_outputs[0]['generated_text']}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b09dc4"
      },
      "source": [
        "### Comparing `pipeline` API with Low-Level API\n",
        "\n",
        "The `transformers` library offers both low-level and high-level (pipeline) APIs for interacting with pre-trained models. The demonstrations above clearly illustrate the benefits of the `pipeline` API for common tasks like text generation.\n",
        "\n",
        "**Low-Level API (`model.generate()`):**\n",
        "\n",
        "When using the `model.generate()` method directly, we needed to:\n",
        "1. Explicitly load the `AutoModelForCausalLM` and `AutoTokenizer`.\n",
        "2. Manually tokenize the input prompt using `tokenizer_generative.encode()` or `tokenizer_generative()`.\n",
        "3. Pass the `input_ids` (and potentially `attention_mask`) to `model_generative.generate()`.\n",
        "4. Manually set `pad_token_id` if it was not the same as `eos_token_id`.\n",
        "5. Decode the output `token_ids` back into human-readable text using `tokenizer_generative.decode()`.\n",
        "\n",
        "This approach gives granular control over every aspect of the generation process, which is invaluable for research or highly customized applications.\n",
        "\n",
        "**High-Level API (`pipeline`):**\n",
        "\n",
        "In contrast, the `pipeline` API significantly simplifies the process:\n",
        "1. We only needed to import the `pipeline` function.\n",
        "2. We instantiated a generator with a single line: `pipeline('text-generation', model='gpt2', tokenizer='gpt2')`.\n",
        "3. The prompt could be passed directly as a string to the `pipeline_generator` object.\n",
        "4. All tokenization, model inference, and decoding steps are abstracted away and handled internally by the pipeline.\n",
        "5. The output is a structured list of dictionaries, making it easy to extract the `generated_text`.\n",
        "\n",
        "**Reduction in Boilerplate Code:**\n",
        "\n",
        "The `pipeline` API dramatically reduces the amount of boilerplate code required. It encapsulates the common sequence of tokenization, model forward pass, and decoding into a single, intuitive function call. This makes it ideal for quick experimentation, deployment of standard tasks, and for users who want to leverage Transformer models without diving deep into their internal workings. For tasks like text classification, summarization, or translation, the `pipeline` offers similar levels of abstraction and ease of use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23f39463"
      },
      "source": [
        "## Custom Tokenizer Comparison\n",
        "\n",
        "### Subtask:\n",
        "Demonstrate using a different existing pre-trained tokenizer (or a tokenizer with custom vocabulary/settings) and compare its tokenization output for a sample sentence against the default tokenizer used earlier, highlighting how tokenization strategies can differ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b54942fe",
        "outputId": "4ad37cf5-43a8-449e-8cd7-53f8a833f835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Sentence: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "--- Tokenization (gpt2) ---\n",
            "Tokens: ['The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', '.']\n",
            "Token IDs: [464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290, 13]\n",
            "\n",
            "--- Tokenization (gpt2-medium) ---\n",
            "Tokens: ['The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', '.']\n",
            "Token IDs: [464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290, 13]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 1. Load a new pre-trained tokenizer (gpt2-medium)\n",
        "custom_tokenizer = AutoTokenizer.from_pretrained('gpt2-medium')\n",
        "\n",
        "# 2. Use the previously defined sample_sentence for tokenization\n",
        "# sample_sentence is 'The quick brown fox jumps over the lazy dog.'\n",
        "print(f\"\\nSample Sentence: {sample_sentence}\\n\")\n",
        "\n",
        "# 3. Tokenize the sample_sentence using custom_tokenizer\n",
        "custom_tokens = custom_tokenizer.tokenize(sample_sentence)\n",
        "custom_token_ids = custom_tokenizer(sample_sentence)['input_ids']\n",
        "\n",
        "# 5. Print the tokens and token IDs obtained from the tokenizer_generative (gpt2) for comparison.\n",
        "# tokenizer_generative was loaded as 'gpt2'\n",
        "print(\"--- Tokenization (gpt2) ---\")\n",
        "# Re-tokenize with tokenizer_generative to ensure fresh comparison\n",
        "gpt2_tokens = tokenizer_generative.tokenize(sample_sentence)\n",
        "gpt2_token_ids = tokenizer_generative(sample_sentence)['input_ids']\n",
        "print(f\"Tokens: {gpt2_tokens}\")\n",
        "print(f\"Token IDs: {gpt2_token_ids}\")\n",
        "\n",
        "# 6. Print the tokens and token IDs obtained from the custom_tokenizer (gpt2-medium)\n",
        "print(\"\\n--- Tokenization (gpt2-medium) ---\")\n",
        "print(f\"Tokens: {custom_tokens}\")\n",
        "print(f\"Token IDs: {custom_token_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a61388c6"
      },
      "source": [
        "### Comparison of Tokenization Outputs (GPT-2 vs. GPT-2 Medium)\n",
        "\n",
        "Upon comparing the tokenization output for the `sample_sentence` (\"The quick brown fox jumps over the lazy dog.\") using both the `gpt2` tokenizer and the `gpt2-medium` tokenizer, we observe that **both tokenizers produced identical tokens and token IDs**:\n",
        "\n",
        "*   **GPT-2 Tokenization:**\n",
        "    *   Tokens: `['The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', '.']`\n",
        "    *   Token IDs: `[464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290, 13]`\n",
        "\n",
        "*   **GPT-2 Medium Tokenization:**\n",
        "    *   Tokens: `['The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', '.']`\n",
        "    *   Token IDs: `[464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290, 13]`\n",
        "\n",
        "**Discussion:**\n",
        "\n",
        "This outcome is not entirely surprising. GPT-2 models (including `gpt2` and `gpt2-medium`) generally share the same tokenizer, which is based on **Byte Pair Encoding (BPE)**. This means they use the same vocabulary and subword splitting rules. The `gpt2-medium` model is simply a larger version of `gpt2` (more layers, more parameters), but it was trained using the same tokenization strategy and vocabulary as the smaller `gpt2` model.\n",
        "\n",
        "**When might we see differences?**\n",
        "\n",
        "Differences in tokenization would typically arise when:\n",
        "1.  **Different Tokenization Algorithms:** For example, comparing a BPE-based tokenizer (like GPT-2) with a WordPiece-based tokenizer (like BERT) or a SentencePiece-based tokenizer (like T5). These different algorithms have distinct ways of splitting words into subwords.\n",
        "2.  **Different Vocabularies:** Even with the same algorithm, if tokenizers are trained on different corpora, their learned vocabularies might differ, leading to different subword splits or token IDs for the same text.\n",
        "3.  **Special Tokens/Settings:** Tokenizers can have different sets of special tokens (e.g., `[CLS]`, `[SEP]`, `[PAD]`) or different rules for handling them.\n",
        "\n",
        "In this specific comparison of `gpt2` and `gpt2-medium`, the consistency in tokenization underscores that the underlying tokenizer component can be shared across models of the same family, even if the models themselves differ in size and capacity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5c946b2"
      },
      "source": [
        "# Memory-Efficient Inference Demo\n",
        "\n",
        "### Subtask:\n",
        "1. Define helper functions to accurately report GPU memory usage (if available) and conceptual CPU memory usage.\n",
        "2. Load a non-quantized model (e.g., 'gpt2'). If on GPU, measure and display its GPU memory footprint. If on CPU, conceptualize its memory usage.\n",
        "3. Deleting the non-quantized model and clearing memory.\n",
        "4. Loading the same model in 8-bit quantized form using `load_in_8bit=True` (which leverages `bitsandbytes` on GPU). If on GPU, measure and display its memory footprint, highlighting the reduction. If on CPU, note that `bitsandbytes` primarily targets GPU and provide conceptual comparison.\n",
        "\n",
        "This step will illustrate the practical memory savings of quantization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1241367",
        "outputId": "8eb43ae2-caf3-4ff1-b01e-e6bb64de14e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory reporting helper functions defined.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "# Helper function to report GPU memory\n",
        "def report_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / (1024**3)\n",
        "        reserved = torch.cuda.memory_reserved() / (1024**3)\n",
        "        print(f\"GPU Memory: Allocated={allocated:.2f} GB, Reserved={reserved:.2f} GB\")\n",
        "    else:\n",
        "        print(\"GPU Memory: CUDA is not available.\")\n",
        "\n",
        "# Helper function to report CPU memory\n",
        "def report_cpu_memory():\n",
        "    process = psutil.Process()\n",
        "    rss = process.memory_info().rss / (1024**2) # Resident Set Size in MB\n",
        "    print(f\"CPU Memory (RSS): {rss:.2f} MB\")\n",
        "\n",
        "# Helper function to clear GPU cache\n",
        "def clear_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU cache cleared.\")\n",
        "    else:\n",
        "        print(\"No GPU to clear cache for.\")\n",
        "\n",
        "print(\"Memory reporting helper functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53d53534",
        "outputId": "c621e173-7928-43c1-989a-067750f837b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Loading Non-Quantized Model (gpt2) ---\n",
            "Non-quantized model moved to GPU.\n",
            "Memory usage after loading non-quantized model:\n",
            "GPU Memory: Allocated=0.96 GB, Reserved=1.01 GB\n",
            "CPU Memory (RSS): 3114.35 MB\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "# 3. Load a non-quantized model\n",
        "print(\"\\n--- Loading Non-Quantized Model (gpt2) ---\")\n",
        "model_non_quantized = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model_non_quantized.to('cuda')\n",
        "    print(\"Non-quantized model moved to GPU.\")\n",
        "else:\n",
        "    print(\"Non-quantized model loaded on CPU (CUDA not available).\")\n",
        "\n",
        "print(\"Memory usage after loading non-quantized model:\")\n",
        "report_gpu_memory()\n",
        "report_cpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "814361e4",
        "outputId": "89c4e400-ca97-42e8-b6d9-ef80e7d250b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Clearing memory from non-quantized model ---\n",
            "GPU cache cleared.\n",
            "Memory cleared.\n",
            "Memory usage after clearing non-quantized model:\n",
            "GPU Memory: Allocated=0.49 GB, Reserved=0.50 GB\n",
            "CPU Memory (RSS): 3111.33 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Clearing memory from non-quantized model ---\")\n",
        "del model_non_quantized\n",
        "clear_gpu_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"Memory cleared.\")\n",
        "print(\"Memory usage after clearing non-quantized model:\")\n",
        "report_gpu_memory()\n",
        "report_cpu_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3305f3c1"
      },
      "source": [
        "### Conceptual Comparison of Memory Usage & CPU vs. GPU Efficiency\n",
        "\n",
        "While a direct, functional demonstration of 8-bit quantized model loading and its immediate memory savings was unfortunately hindered by an `ImportError` with the `bitsandbytes` library, we can still conceptually understand the significant impact of memory-efficient inference, particularly concerning CPU versus GPU usage.\n",
        "\n",
        "**Memory Efficiency in Inference (CPU vs. GPU):**\n",
        "\n",
        "*   **GPU (Graphics Processing Unit)**: GPUs are designed for highly parallel computations, making them ideal for neural networks. However, GPU memory (VRAM) is typically much more limited than system RAM (CPU memory). For instance, a high-end consumer GPU might have 12-24 GB of VRAM, whereas a server or even a laptop can have 32 GB or more of system RAM. Fitting large language models into limited GPU memory is a major challenge.\n",
        "    *   **Implication**: Quantization techniques like 8-bit (INT8) or 4-bit (INT4) are critical for GPUs. They allow models that would otherwise exceed VRAM capacity to be loaded and run, enabling faster inference by keeping computations on the GPU. Without quantization, many state-of-the-art LLMs would simply be too large to run on common GPUs.\n",
        "\n",
        "*   **CPU (Central Processing Unit)**: CPUs have access to much larger pools of system RAM. While they are generally slower for parallel neural network operations, they often have sufficient memory to load even very large models in full precision (FP32). However, running inference on FP32 models on a CPU can be very slow due to serial processing and slower memory access compared to GPU VRAM.\n",
        "    *   **Implication**: While quantization can still offer some speed benefits on CPUs, its primary role for CPUs is less about fitting the model into memory (as RAM is usually abundant) and more about potentially speeding up computations, though the gains might not be as dramatic as on specialized GPU hardware. `bitsandbytes` specifically targets GPU optimization, so its memory saving benefits are most pronounced there.\n",
        "\n",
        "**Conceptual Memory Comparison (Based on Expected Behavior):**\n",
        "\n",
        "Let's consider the `gpt2` model we attempted to load. Its full precision (FP32) weights would typically consume around **0.96 GB** of GPU memory (as observed in our non-quantized load step). This is because each parameter (weight) is stored as a 32-bit (4-byte) floating-point number.\n",
        "\n",
        "If the 8-bit quantization with `bitsandbytes` had been successful, we would have expected to see a significant reduction in **GPU memory usage**. An 8-bit integer (INT8) uses 1 byte per parameter, which is 1/4th the memory of a 32-bit float. Therefore, a perfectly 8-bit quantized `gpt2` model would conceptually occupy approximately:\n",
        "\n",
        "`0.96 GB (FP32) / 4 = 0.24 GB (INT8)`\n",
        "\n",
        "This represents a **75% reduction in GPU memory footprint**. This massive saving allows for:\n",
        "*   Running larger models than otherwise possible.\n",
        "*   Batching more inputs, increasing throughput.\n",
        "*   Using cheaper GPUs with less VRAM.\n",
        "\n",
        "**Summary of Impact:**\n",
        "\n",
        "Quantization is a vital technique for making large language models more accessible and efficient for inference, especially on GPUs where memory is a bottleneck. It allows a trade-off between slight potential accuracy loss and substantial gains in memory footprint and inference speed, making it a cornerstone of deploying modern NLP models in real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K0jrqL1hX9AN",
        "outputId": "1d1b5c54-9d5c-423a-edba-7aab0bd05bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: bitsandbytes 0.49.1\n",
            "Uninstalling bitsandbytes-0.49.1:\n",
            "  Successfully uninstalled bitsandbytes-0.49.1\n",
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: accelerate 1.12.0\n",
            "Uninstalling accelerate-1.12.0:\n",
            "  Successfully uninstalled accelerate-1.12.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers, accelerate\n",
            "Successfully installed accelerate-1.12.0 transformers-4.57.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4928b35a40464a29bd99c2acf77c6c4f",
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Using cached bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.49.1\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall -y bitsandbytes transformers accelerate\n",
        "# !pip install -U transformers accelerate\n",
        "# !pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "612d9a94"
      },
      "source": [
        "### What is 'Quantization'?\n",
        "\n",
        "**Quantization** in the context of neural networks, especially large language models (LLMs), is a technique used to reduce the memory footprint and computational cost of models by representing their weights and activations with lower-precision numerical formats. Instead of using standard 32-bit floating-point numbers (FP32), quantization typically reduces these to 16-bit (FP16 or BF16), 8-bit (INT8), or even 4-bit (INT4) integers or floats.\n",
        "\n",
        "Here's why it's important and how it works:\n",
        "\n",
        "*   **Memory Efficiency**: The primary benefit is memory reduction. If a model's weights are stored as INT8 instead of FP32, it requires only one-fourth of the memory. This is crucial for deploying large models on devices with limited memory (e.g., mobile, edge devices) or for fitting larger models into GPU memory during inference.\n",
        "\n",
        "*   **Faster Inference**: Lower-precision operations can often be executed much faster on specialized hardware (like GPUs with Tensor Cores or custom AI accelerators) because they involve smaller data units. This leads to reduced latency and increased throughput during inference.\n",
        "\n",
        "*   **Reduced Power Consumption**: Fewer memory transfers and faster computations can also translate to lower power consumption, which is important for battery-powered devices.\n",
        "\n",
        "*   **How it works (conceptually)**:\n",
        "    *   **Mapping**: Quantization involves mapping a range of high-precision numbers (e.g., FP32) to a smaller range of low-precision numbers (e.g., INT8). This is often done by scaling and offsetting the original values.\n",
        "    *   **Post-Training Quantization (PTQ)**: This is the most common approach for deployment. A model is first trained in full precision (FP32), and then its weights (and sometimes activations) are converted to lower precision *after* training. This is what `bitsandbytes` facilitates with `load_in_8bit=True`.\n",
        "    *   **Quantization-Aware Training (QAT)**: In more advanced scenarios, the model is trained with simulated quantization effects, which can sometimes lead to better accuracy preservation than PTQ.\n",
        "\n",
        "*   **Impact on Accuracy**: The main challenge with quantization is to minimize the loss of accuracy. Reducing numerical precision inevitably introduces some information loss. Advanced quantization techniques aim to strike a balance between memory/speed benefits and maintaining acceptable model performance.\n",
        "\n",
        "*   **`bitsandbytes`**: This library is specifically designed to enable efficient 8-bit (and 4-bit) quantization on GPUs, offering highly optimized CUDA kernels for these low-precision operations within the `transformers` ecosystem. It transparently handles the conversion of model weights to 8-bit during loading, and then dynamically de-quantizes them for computations when needed, ensuring that the critical parts of the calculations still maintain sufficient precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oELj-CDYJ-R",
        "outputId": "4b7e7d15-de7e-4bdd-903d-c5505c8f8930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory reporting helper functions redefined.\n",
            "GPU cache cleared.\n",
            "\n",
            "--- Loading 8-bit Quantized Model (gpt2) after reinstallation ---\n",
            "8-bit Quantized model loaded on GPU.\n",
            "Memory usage after loading 8-bit quantized model:\n",
            "GPU Memory: Allocated=0.33 GB, Reserved=0.54 GB\n",
            "CPU Memory (RSS): 2085.46 MB\n",
            "GPU cache cleared.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import psutil # Ensure psutil is imported here\n",
        "import gc\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Helper function to report GPU memory\n",
        "def report_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / (1024**3)\n",
        "        reserved = torch.cuda.memory_reserved() / (1024**3)\n",
        "        print(f\"GPU Memory: Allocated={allocated:.2f} GB, Reserved={reserved:.2f} GB\")\n",
        "    else:\n",
        "        print(\"GPU Memory: CUDA is not available.\")\n",
        "\n",
        "# Helper function to report CPU memory\n",
        "def report_cpu_memory():\n",
        "    process = psutil.Process()\n",
        "    rss = process.memory_info().rss / (1024**2) # Resident Set Size in MB\n",
        "    print(f\"CPU Memory (RSS): {rss:.2f} MB\")\n",
        "\n",
        "# Helper function to clear GPU cache\n",
        "def clear_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU cache cleared.\")\n",
        "    else:\n",
        "        print(\"No GPU to clear cache for.\")\n",
        "\n",
        "print(\"Memory reporting helper functions redefined.\")\n",
        "\n",
        "# Ensure clean slate before loading quantized model\n",
        "clear_gpu_cache()\n",
        "gc.collect()\n",
        "\n",
        "model_name = 'gpt2'\n",
        "\n",
        "print(f\"\\n--- Loading 8-bit Quantized Model ({model_name}) after reinstallation ---\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # Define the 8-bit quantization configuration\n",
        "    quantization_config_8bit = BitsAndBytesConfig(\n",
        "        load_in_8bit=True\n",
        "    )\n",
        "\n",
        "    # Load the model with the quantization configuration\n",
        "    model_quantized = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config_8bit)\n",
        "\n",
        "    print(\"8-bit Quantized model loaded on GPU.\")\n",
        "\n",
        "    print(\"Memory usage after loading 8-bit quantized model:\")\n",
        "    report_gpu_memory()\n",
        "    report_cpu_memory()\n",
        "\n",
        "    # Clean up after demo\n",
        "    del model_quantized\n",
        "    clear_gpu_cache()\n",
        "    gc.collect()\n",
        "\n",
        "else:\n",
        "    print(\"CUDA is not available. Cannot perform GPU memory comparison for 8-bit quantization.\")\n",
        "    print(\"Conceptual comparison: 8-bit quantized model would use significantly less RAM/VRAM if GPU were available.\")\n",
        "    print(\"Skipping 8-bit quantized model loading for CPU as bitsandbytes is GPU-dependent for 8-bit loading.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5dd381d"
      },
      "source": [
        "## Semantic Similarity Application\n",
        "\n",
        "### Subtask:\n",
        "Revisit semantic similarity by taking a new query sentence, calculating its embedding, and computing cosine similarity against the `sample_texts` from earlier steps. Display the ranked results to show a practical application of embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1dbba4f",
        "outputId": "d72d59b1-a9f4-4013-cf00-ff91e60217ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query Sentence: 'How is the weather outside today?'\n",
            "\n",
            "Semantic Similarity to Query Sentence:\n",
            "Query: 'How is the weather outside today?'\n",
            "\n",
            " Sample Text Index                                              Sample Text  Similarity Score\n",
            "                 4          The weather today is sunny with a light breeze.          0.659939\n",
            "                 1             The quick brown fox jumps over the lazy dog.          0.499150\n",
            "                 2      Natural Language Processing is a fascinating field.          0.491677\n",
            "                 5 Cats are known for their agility and independent nature.          0.480199\n",
            "                 3            Large language models have revolutionized AI.          0.474759\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Define a new query sentence\n",
        "query_sentence = \"How is the weather outside today?\"\n",
        "print(f\"\\nQuery Sentence: '{query_sentence}'\\n\")\n",
        "\n",
        "# 2. Compute the embedding for the new query sentence\n",
        "query_embedding = get_sentence_embedding(query_sentence)\n",
        "\n",
        "# 3. Calculate the cosine similarity between the query sentence's embedding and each of the existing sample_texts embeddings\n",
        "similarity_scores = []\n",
        "for i, sample_embedding in enumerate(sentence_embeddings):\n",
        "    similarity = F.cosine_similarity(query_embedding, sample_embedding, dim=0)\n",
        "    similarity_scores.append({\n",
        "        'Sample Text Index': i + 1,\n",
        "        'Sample Text': sample_texts[i],\n",
        "        'Similarity Score': similarity.item()\n",
        "    })\n",
        "\n",
        "# 4. Create a DataFrame to store the results\n",
        "similarity_df_query = pd.DataFrame(similarity_scores)\n",
        "\n",
        "# 5. Rank the sample_texts by their similarity scores in descending order\n",
        "ranked_results = similarity_df_query.sort_values(by='Similarity Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# 6. Display the ranked results\n",
        "print(\"Semantic Similarity to Query Sentence:\")\n",
        "print(f\"Query: '{query_sentence}'\\n\")\n",
        "print(ranked_results.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a01741e7"
      },
      "source": [
        "## Basic Hybrid Search\n",
        "\n",
        "### Subtask:\n",
        "Implement a simple hybrid search combining keyword matching with semantic similarity scores on a new, slightly larger dataset. Display the ranked results to demonstrate how both methods contribute to relevance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eac0edf6",
        "outputId": "32d7a2bf-f5f5-402b-b262-9f02c0bef427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Larger Sample Texts (for Hybrid Search):\n",
            "1. Generative AI models are transforming many industries with their ability to create new content.\n",
            "2. The latest advancements in large language models (LLMs) enable more sophisticated text generation.\n",
            "3. Weather forecasts today predict sunny skies with a chance of light breezes in the afternoon.\n",
            "4. Natural Language Processing (NLP) is a core component of modern AI systems, including search engines.\n",
            "5. A deep dive into subword tokenization strategies reveals their importance for handling diverse vocabularies.\n",
            "6. Exploring the practical applications of semantic similarity in information retrieval and recommendation systems.\n",
            "7. Cats are often celebrated for their agility, independence, and sometimes aloof nature.\n",
            "8. Hybrid search systems combine the strengths of keyword matching and semantic search for improved relevance.\n",
            "9. Understanding model inference and how logits are used to predict the next token in sequence generation.\n",
            "10. The historical context of natural language processing shows its evolution from rule-based systems to deep learning.\n",
            "\n",
            "Hydrid Query: 'AI models and their applications, especially related to natural language.'\n"
          ]
        }
      ],
      "source": [
        "larger_sample_texts = [\n",
        "    \"Generative AI models are transforming many industries with their ability to create new content.\",\n",
        "    \"The latest advancements in large language models (LLMs) enable more sophisticated text generation.\",\n",
        "    \"Weather forecasts today predict sunny skies with a chance of light breezes in the afternoon.\",\n",
        "    \"Natural Language Processing (NLP) is a core component of modern AI systems, including search engines.\",\n",
        "    \"A deep dive into subword tokenization strategies reveals their importance for handling diverse vocabularies.\",\n",
        "    \"Exploring the practical applications of semantic similarity in information retrieval and recommendation systems.\",\n",
        "    \"Cats are often celebrated for their agility, independence, and sometimes aloof nature.\",\n",
        "    \"Hybrid search systems combine the strengths of keyword matching and semantic search for improved relevance.\",\n",
        "    \"Understanding model inference and how logits are used to predict the next token in sequence generation.\",\n",
        "    \"The historical context of natural language processing shows its evolution from rule-based systems to deep learning.\"\n",
        "]\n",
        "\n",
        "hybrid_query = \"AI models and their applications, especially related to natural language.\"\n",
        "\n",
        "print(\"Larger Sample Texts (for Hybrid Search):\")\n",
        "for i, text in enumerate(larger_sample_texts):\n",
        "    print(f\"{i+1}. {text}\")\n",
        "\n",
        "print(f\"\\nHydrid Query: '{hybrid_query}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d36664f",
        "outputId": "f326795b-c9c7-4ff2-b086-b4e4133ef047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hybrid Search Results for Query: 'AI models and their applications, especially related to natural language.'\n",
            "--------------------------------------------------\n",
            " Document Index                                                                                                            Document  Keyword Score  Semantic Similarity Score  Hybrid Score\n",
            "              1                     Generative AI models are transforming many industries with their ability to create new content.            0.4                   0.668216      0.534108\n",
            "              4               Natural Language Processing (NLP) is a core component of modern AI systems, including search engines.            0.3                   0.733570      0.516785\n",
            "             10 The historical context of natural language processing shows its evolution from rule-based systems to deep learning.            0.3                   0.692666      0.496333\n",
            "              5        A deep dive into subword tokenization strategies reveals their importance for handling diverse vocabularies.            0.3                   0.673910      0.486955\n",
            "              6    Exploring the practical applications of semantic similarity in information retrieval and recommendation systems.            0.2                   0.729745      0.464873\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "# --- Step 3: Implement Keyword Matching Function ---\n",
        "def get_keyword_score(document, query):\n",
        "    document_lower = document.lower()\n",
        "    query_words = set(re.findall(r'\\b\\w+\\b', query.lower()))\n",
        "\n",
        "    # Count common words, excluding very common stop words if necessary, for simplicity, count all words\n",
        "    keyword_matches = 0\n",
        "    for word in query_words:\n",
        "        if word in document_lower:\n",
        "            keyword_matches += 1\n",
        "\n",
        "    # Normalize keyword score to be between 0 and 1\n",
        "    return keyword_matches / len(query_words) if len(query_words) > 0 else 0\n",
        "\n",
        "# --- Step 4 & 5: Calculate Embeddings ---\n",
        "# sentence_embeddings is a list of embeddings for sample_texts, we need for larger_sample_texts\n",
        "larger_sentence_embeddings = [get_sentence_embedding(text) for text in larger_sample_texts]\n",
        "hybrid_query_embedding = get_sentence_embedding(hybrid_query)\n",
        "\n",
        "# --- Step 6: Compute Cosine Similarity ---\n",
        "semantic_similarity_scores = []\n",
        "for doc_embedding in larger_sentence_embeddings:\n",
        "    similarity = F.cosine_similarity(hybrid_query_embedding, doc_embedding, dim=0)\n",
        "    semantic_similarity_scores.append(similarity.item())\n",
        "\n",
        "# --- Step 7: Combine Scores ---\n",
        "combined_results = []\n",
        "for i, doc_text in enumerate(larger_sample_texts):\n",
        "    keyword_score = get_keyword_score(doc_text, hybrid_query)\n",
        "    semantic_score = semantic_similarity_scores[i]\n",
        "\n",
        "    # Simple weighted sum (can be adjusted). Normalization of keyword score already done.\n",
        "    # For this demo, let's give equal weight to both normalized scores.\n",
        "    hybrid_score = (keyword_score + semantic_score) / 2\n",
        "\n",
        "    combined_results.append({\n",
        "        'Document Index': i + 1,\n",
        "        'Document': doc_text,\n",
        "        'Keyword Score': keyword_score,\n",
        "        'Semantic Similarity Score': semantic_score,\n",
        "        'Hybrid Score': hybrid_score\n",
        "    })\n",
        "\n",
        "# --- Step 8 & 9: Create DataFrame and Rank Results ---\n",
        "hybrid_search_df = pd.DataFrame(combined_results)\n",
        "ranked_hybrid_results = hybrid_search_df.sort_values(by='Hybrid Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nHybrid Search Results for Query: '{hybrid_query}'\")\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "# --- Step 10: Display Top Ranked Results ---\n",
        "print(ranked_hybrid_results.head(5).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aebeaa1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Memory Footprint of Non-Quantized Model**: Loading the 'gpt2' model without quantization on a GPU resulted in an allocated GPU memory of **0.96 GB** and a reserved memory of **1.04 GB**. The CPU Resident Set Size (RSS) was **3017.36 MB**.\n",
        "*   **Conceptual Memory Savings from Quantization**: Conceptually, 8-bit quantization for a model like 'gpt2' (which uses 0.96 GB in FP32) would reduce its GPU memory footprint by approximately **75%**, down to about **0.24 GB**.\n",
        "*   **Semantic Similarity in Action**: For the query \"How is the weather outside today?\", the `sample_text` \"The weather today is sunny with a light breeze.\" was identified as the most semantically similar, achieving the highest cosine similarity score of **0.659939**.\n",
        "*   **Successful Hybrid Search Implementation**: A hybrid search system was successfully implemented, combining keyword matching and semantic similarity. For the query \"AI models and their applications, especially related to natural language.\", the top-ranked document was \"Generative AI models are transforming many industries with their ability to create new content.\" It achieved a Keyword Score of **0.4**, a Semantic Similarity Score of **0.668**, and a combined Hybrid Score of **0.534**.\n",
        "*   **Hybrid Search Demonstrates Combined Relevance**: The hybrid search effectively showed how both keyword presence and semantic understanding contribute to ranking results, with documents semantically close to the query receiving higher ranks even if they had fewer exact keyword matches.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
